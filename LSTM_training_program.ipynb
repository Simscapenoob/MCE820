{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T07:33:34.450291Z",
     "start_time": "2025-05-14T07:33:34.075003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################### INITIALIZATION #####################\n",
    "%reset -f\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "n=93000 #Number of datapoints\n",
    "sf=2600 #scaling factor\n",
    "torch.cuda.is_available()\n",
    "print(torch.version.cuda)\n",
    "\n",
    "################### DATA IMPORT #####################\n",
    "\n",
    "df = pd.read_csv('PLL_speed.csv').iloc[:n]\n",
    "print(df.head)\n",
    "\n",
    "X_train_speed = df['predictors']  \n",
    "X_train_for_plot = df['predictors']\n",
    "\n",
    "plt.plot(X_train_speed)\n",
    "df = pd.read_csv('ia.csv').iloc[:n]\n",
    "print(df.head)\n",
    "\n",
    "X_train_a = df['predictors']\n",
    "X_train_for_plot = df['predictors']\n",
    "\n",
    "plt.plot(X_train_a)\n",
    "df = pd.read_csv('ib.csv').iloc[:n]\n",
    "print(df.head)\n",
    "\n",
    "X_train_b = df['predictors']  \n",
    "X_train_for_plot = df['predictors']\n",
    "\n",
    "plt.plot(X_train_b)\n",
    "df = pd.read_csv('ic.csv').iloc[:n]\n",
    "print(df.head)\n",
    "\n",
    "X_train_c = df['predictors']  \n",
    "X_train_for_plot = df['predictors']\n",
    "\n",
    "plt.plot(X_train_c)\n",
    "\n",
    "df = pd.read_csv('Vafa.csv').iloc[:n]\n",
    "print(df.head)\n",
    "X_train_Vafa = df['predictors']  \n",
    "X_train_for_plot = df['predictors']\n",
    "\n",
    "plt.plot(X_train_Vafa)\n",
    "df = pd.read_csv('Vbet.csv').iloc[:n]\n",
    "print(df.head)\n",
    "X_train_Vbet = df['predictors']  \n",
    "X_train_for_plot = df['predictors']\n",
    "\n",
    "plt.plot(X_train_Vbet)\n",
    "df = pd.read_csv('N_measure.csv').iloc[:n]\n",
    "print(df.head)\n",
    "y_train = df['ground_truth']/sf\n",
    "plt.plot(y_train)\n",
    "\n",
    "################### TENSOR CREATION #####################\n",
    "\n",
    "# Convert input arrays to float tensors\n",
    "X_train_speed = torch.tensor(X_train_speed, dtype=torch.float32)\n",
    "X_train_a = torch.tensor(X_train_a, dtype=torch.float32)\n",
    "X_train_b = torch.tensor(X_train_b, dtype=torch.float32)\n",
    "X_train_c = torch.tensor(X_train_c, dtype=torch.float32)\n",
    "X_train_Vafa = torch.tensor(X_train_Vafa, dtype=torch.float32)\n",
    "X_train_Vbet = torch.tensor(X_train_Vbet, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_train_for_plot = torch.tensor(X_train_for_plot, dtype=torch.float32)\n",
    "\n",
    "print(X_train_a.shape)\n",
    "\n",
    "# Stack all 5 features along a new last dimension to create (time_steps, 5)\n",
    "X_combined = torch.stack([X_train_speed/sf, X_train_a/sf, X_train_b/sf, X_train_c/sf, X_train_Vafa/sf, X_train_Vbet/sf], dim=1)\n",
    "# Now shape is: (total_time_steps, 5)\n",
    "\n",
    "window_size = 200\n",
    "# Create windows: (num_windows, window_size, 5)\n",
    "X_windows = torch.stack([X_combined[i:i+window_size] for i in range(len(X_combined) - window_size)])\n",
    "\n",
    "# Target values aligned with the end of each window\n",
    "y_windows = y_train[window_size:]\n",
    "X_train_for_plot = X_train_for_plot[window_size:]\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f\"Shape of X_windows: {X_windows.shape}\")  \n",
    "print(f\"Shape of y_windows: {y_windows.shape}\")\n",
    "\n",
    "\n",
    "Testlengt=5000 #Data left out, to use for validation\n",
    "\n",
    "x_train = X_windows[:len(X_windows)-Testlengt]\n",
    "y_train = y_windows[:len(y_windows)-Testlengt]\n",
    "\n",
    "x_test = X_windows[-Testlengt:]\n",
    "\n",
    "y_train = y_train.unsqueeze(1)\n",
    "y_test = y_windows[-Testlengt:].unsqueeze(1)\n",
    "\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "print(f\"Shape of x_train: {x_train.shape}\")\n",
    "print(f\"Shape of x_test: {x_test.shape}\")\n",
    "\n",
    "################## NETWORK DEFINITION AND TRAINING #############################\n",
    "\n",
    "HIDDEN_SIZE = 48  # Number of units in LSTM hidden layers\n",
    "NUM_LAYERS = 1  # Number of LSTM layers\n",
    "BATCH_SIZE = 49  # Number of samples per batch during training\n",
    "EPOCHS = 93  # Number of training iterations over the dataset\n",
    "LR = 0.001  # Learning rate for optimizer\n",
    "\n",
    "# Create DataLoader for training (handles batching and shuffling)\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(x_train, y_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    pin_memory=True, # Faster transfer to CUDA\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define the LSTM model class\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=6, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS):\n",
    "        super(LSTMModel, self).__init__()  # Initialize parent class\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)  # Define LSTM layer\n",
    "        self.fc = nn.Linear(hidden_size, 1)  # Fully connected layer to produce final output\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # Forward pass through LSTM\n",
    "        out = self.fc(out[:, -1, :])  # Take the last time step's output and pass it through FC layer\n",
    "        return out  # Return predicted value\n",
    "\n",
    "# Initialize the model and move it to the selected device\n",
    "model = LSTMModel().to(device)\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Define the loss function (Mean Squared Error) and optimizer (Adam)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Training function\n",
    "def train(model, train_loader, epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(epochs):  # Loop through epochs\n",
    "        total_loss = 0  # Initialize total loss for epoch\n",
    "        for x_batch, y_batch in train_loader:  # Loop through batches\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move data to device\n",
    "\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            y_pred = model(x_batch)  # Forward pass to get predictions\n",
    "            loss = criterion(y_pred, y_batch)  # Compute loss\n",
    "            loss.backward()  # Backpropagation to compute gradients\n",
    "            optimizer.step()  # Update model weights using optimizer\n",
    "            total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Print average loss per epoch\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(train_loader):.9f}\")\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, EPOCHS)\n",
    "\n",
    "\n",
    "\n",
    "########### VISUALLY EVALUATE THE MODEL ######################\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    x_test = x_test.to(device)#x_test.to(device)\n",
    "    y_test = y_test.to(device)#y_test.to(device)  # Move test data to device\n",
    "    y_pred = model(x_test).cpu().numpy()  # Get predictions and move them to CPU\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6), dpi=500)  \n",
    "plt.plot(y_test.cpu().numpy().squeeze(1), label=\"Actual\", color=\"blue\", linewidth=2)  \n",
    "plt.plot(y_pred, label=\"Predicted\", color=\"red\", linestyle=\"dashed\", linewidth=2)  \n",
    "plt.legend(fontsize=12) \n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)  \n",
    "plt.title(\"LSTM Sine Wave Prediction\", fontsize=14)  \n",
    "plt.xlabel(\"Time Step\", fontsize=12) \n",
    "plt.ylabel(\"Amplitude\", fontsize=12) \n",
    "plt.show()  \n",
    "\n",
    "################# SAVE PARAMETERS TO .mat FILE ######################\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "lstm = model.lstm  \n",
    "\n",
    "# Extract weights and biases\n",
    "\n",
    "weight_ih = lstm.weight_ih_l0.cpu().detach().numpy()  # shape (4*hidden_size, input_size)\n",
    "weight_hh = lstm.weight_hh_l0.cpu().detach().numpy()  # shape (4*hidden_size, hidden_size)\n",
    "bias_ih = lstm.bias_ih_l0.cpu().detach().numpy()      # shape (4*hidden_size)\n",
    "bias_hh = lstm.bias_hh_l0.cpu().detach().numpy()       # shape (4*hidden_size)\n",
    "\n",
    "# Sum the input and hidden biases (PyTorch separates them)\n",
    "bias = bias_ih + bias_hh\n",
    "\n",
    "# Now split everything into the 4 gates\n",
    "hidden_size = lstm.hidden_size\n",
    "\n",
    "Wf = weight_hh[0:hidden_size, :]  # hidden -> forget gate\n",
    "Wi = weight_hh[hidden_size:2*hidden_size, :]  # hidden -> input gate\n",
    "Wc = weight_hh[2*hidden_size:3*hidden_size, :]  # hidden -> cell gate\n",
    "Wo = weight_hh[3*hidden_size:4*hidden_size, :]  # hidden -> output gate\n",
    "\n",
    "Uf = weight_ih[0:hidden_size, :]  # input -> forget gate\n",
    "Ui = weight_ih[hidden_size:2*hidden_size, :]  # input -> input gate\n",
    "Uc = weight_ih[2*hidden_size:3*hidden_size, :]  # input -> cell gate\n",
    "Uo = weight_ih[3*hidden_size:4*hidden_size, :]  # input -> output gate\n",
    "\n",
    "bf = bias[0:hidden_size]  # bias for forget gate\n",
    "bi = bias[hidden_size:2*hidden_size]  # bias for input gate\n",
    "bc = bias[2*hidden_size:3*hidden_size]  # bias for cell gate\n",
    "bo = bias[3*hidden_size:4*hidden_size]  # bias for output gate\n",
    "\n",
    "# (Optional) Linear layer afterward\n",
    "Wout = model.fc.weight.cpu().detach().numpy()  # shape (output_size, hidden_size)\n",
    "bout = model.fc.bias.cpu().detach().numpy()    # shape (output_size)\n",
    "\n",
    "# Save everything into a .mat file\n",
    "scipy.io.savemat('lstm_parameters4.mat', {\n",
    "    'Wf': Wf,\n",
    "    'Uf': Uf,\n",
    "    'bf': bf,\n",
    "    'Wi': Wi,\n",
    "    'Ui': Ui,\n",
    "    'bi': bi,\n",
    "    'Wo': Wo,\n",
    "    'Uo': Uo,\n",
    "    'bo': bo,\n",
    "    'Wc': Wc,\n",
    "    'Uc': Uc,\n",
    "    'bc': bc,\n",
    "    'Wout': Wout,\n",
    "    'bout': bout\n",
    "})\n",
    "\n",
    "print(\"Saved parameters to lstm_parameters4.mat ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
